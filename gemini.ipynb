{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/scrape-linkedIn/linkedin_scraper/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If your API key is valid. All available models will be listed below...\n",
      "PaLM 2 Chat (Legacy)\n",
      "PaLM 2 (Legacy)\n",
      "Embedding Gecko\n",
      "Gemini 1.0 Pro\n",
      "Gemini 1.0 Pro 001 (Tuning)\n",
      "Gemini 1.0 Pro Latest\n",
      "Gemini 1.0 Pro Vision\n",
      "Gemini 1.5 Flash\n",
      "Gemini 1.5 Pro\n",
      "Gemini 1.0 Pro\n",
      "Gemini 1.0 Pro Vision\n",
      "Embedding 001\n",
      "Text Embedding 004\n",
      "Model that performs Attributed Question Answering.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if load_dotenv(\"dotfiles/.env\"):\n",
    "        genai.configure(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "        models = genai.list_models()\n",
    "        print(\"If your API key is valid. All available models will be listed below...\")\n",
    "        for model in models:\n",
    "            print(model.display_name)\n",
    "except Exception as e:\n",
    "    print(\"API KEY is invalid!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "# See https://ai.google.dev/api/python/google/generativeai/GenerativeModel\n",
    "generation_config = {\n",
    "  \"temperature\": 1.0,\n",
    "  \"top_p\": 1,\n",
    "  \"top_k\": 0,\n",
    "  \"max_output_tokens\": 14000,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "safety_settings = [\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
    "  },\n",
    "]\n",
    "\n",
    "system_instruction = '''You are an agent that takes in a given piece of text and then creates a dictionary accordingly. \\\n",
    "                        You are given a person's professional experience where you have to convert it into key, value pairs in the following manner where the keys signify: \\\n",
    "                        Company, Role, Location, Start_Date, End_Date, Duration, Type_of_work(on-site, hybrid, remote), Description, Skills_Used. \\\n",
    "                        Note that you have to only use Strings enclosed in triple quotes for the value of Description key, the rest using normal double quotes; \\ \n",
    "                        but include a list of skills for Skills_Used.\n",
    "                        Enclose all of the generated dictionaries into a super dictionary with key_name as Experience wherein each individual experience is take as \\\n",
    "                        key, value pairs: key: numbers(starting from zero), values being each professional experience.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.0-pro\",\n",
    "  safety_settings=safety_settings,\n",
    "  generation_config=generation_config,\n",
    "  # system_instruction=system_instruction\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience = '''\n",
    "Jaws Shark\n",
    "Full-time · 2 yrs\n",
    "Another temporary experience\n",
    "May 2023 to Present · 1 yr 1 mo\n",
    "Hyderabad, Telangana, India · Hybrid\n",
    "Temporary, not permanent.\n",
    "Fishing · Sailing\n",
    "Temporary Experience (For a scraper that I am building)\n",
    "Jun 2022 to May 2023 · 1 yr\n",
    "Visakhapatnam, Andhra Pradesh, India · On-site\n",
    "Nothing much to say other than that this is temporary\n",
    "Team Leadership · Fishing\n",
    "Machine Learning Summer Intern\n",
    "CloudKarya, Inc · Internship\n",
    "Apr 2023 to Jun 2023 · 3 mos\n",
    "Visakhapatnam, Andhra Pradesh, India · On-site\n",
    "Developed a Deep Learning solution to detect the presence of Retinal Diseases. The website has been deployed on Google Cloud Platform and available for public use: https://dev-ikshana-dw5whmz2hq-ue.a.run.app/getdata Techstack used: - Docker - Docker Compose - Google Cloud Run - Google Cloud Function - Google Cloud Storage Bucket - Google BigQuery - Convolution-Neural-Networks - Tensorflow - Vanilla Framework (HTML, CSS, Javascript)\n",
    "Team Leadership · docker · Web Development · Google Cloud Platform (GCP) · TensorFlow\n",
    "RPA Developer\n",
    "SS&C Blue Prism · Internship\n",
    "Aug 2022 to Sep 2022 · 2 mos\n",
    "Remote\n",
    "I have been a part of the RPA Developer internship offered as part of AICTE's NEAT program. The internship was provided by EduSkills foundation and SS&C Blue Prism University. I learnt about the basics of RPA and Bot development using Blueprism Studio.\n",
    "Analytical Skills · Blue Prism · Critical Thinking · Robotic Process Automation (RPA)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_session = model.start_chat()\n",
    "initial_response = chat_session.send_message('''\n",
    "You are an agent that takes in a given piece of text and then creates a dictionary accordingly. \\\n",
    "                        You are given a person's professional experience where you have to convert it into key, value pairs in the following manner where the keys signify: \\\n",
    "                        Company, Role, Location, Start_Date, End_Date, Duration, Type_of_work(on-site, hybrid, remote), Description, Skills_Used. \\\n",
    "                        Note that you have to only use Strings enclosed in triple quotes for the value of Description key, the rest using normal double quotes; \\ \n",
    "                        but include a list of skills for Skills_Used.\n",
    "                        Enclose all of the generated dictionaries into a super dictionary with key_name as Experience wherein each individual experience is take as \\\n",
    "                        key, value pairs: key: numbers(starting from zero), values being each professional experience; dont' add anything else. \\\n",
    "                        Generate only the required dictionary, but not as markdown text. That is, do not generate the dictionary as embedded code in Markdown. \\\n",
    "                        Reply only the word 'YES' if you've understood the instruction\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_response = None\n",
    "if initial_response.text == \"YES\":\n",
    "    dictionary_response = chat_session.send_message(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"Experience\": {\n",
      "  \"0\": {\n",
      "   \"Company\": \"Jaws Shark\",\n",
      "   \"Role\": \"Full-time\",\n",
      "   \"Location\": null,\n",
      "   \"Start_Date\": \"May 2023\",\n",
      "   \"End_Date\": \"Present\",\n",
      "   \"Duration\": \"2 yrs\",\n",
      "   \"Type_of_work\": null,\n",
      "   \"Description\": null,\n",
      "   \"Skills_Used\": []\n",
      "  },\n",
      "  \"1\": {\n",
      "   \"Company\": \"Another temporary experience\",\n",
      "   \"Role\": null,\n",
      "   \"Location\": \"Hyderabad, Telangana, India\",\n",
      "   \"Start_Date\": \"May 2023\",\n",
      "   \"End_Date\": \"Present\",\n",
      "   \"Duration\": \"1 yr 1 mo\",\n",
      "   \"Type_of_work\": \"Hybrid\",\n",
      "   \"Description\": \"\\\"Temporary, not permanent.\\\"\",\n",
      "   \"Skills_Used\": [\n",
      "    \"Fishing\",\n",
      "    \"Sailing\"\n",
      "   ]\n",
      "  },\n",
      "  \"2\": {\n",
      "   \"Company\": \"Temporary Experience (For a scraper that I am building)\",\n",
      "   \"Role\": null,\n",
      "   \"Location\": \"Visakhapatnam, Andhra Pradesh, India\",\n",
      "   \"Start_Date\": \"Jun 2022\",\n",
      "   \"End_Date\": \"May 2023\",\n",
      "   \"Duration\": \"1 yr\",\n",
      "   \"Type_of_work\": \"On-site\",\n",
      "   \"Description\": \"\\\"Nothing much to say other than that this is temporary\\\"\",\n",
      "   \"Skills_Used\": [\n",
      "    \"Team Leadership\",\n",
      "    \"Fishing\"\n",
      "   ]\n",
      "  },\n",
      "  \"3\": {\n",
      "   \"Company\": \"CloudKarya, Inc\",\n",
      "   \"Role\": \"Machine Learning Summer Intern\",\n",
      "   \"Location\": \"Visakhapatnam, Andhra Pradesh, India\",\n",
      "   \"Start_Date\": \"Apr 2023\",\n",
      "   \"End_Date\": \"Jun 2023\",\n",
      "   \"Duration\": \"3 mos\",\n",
      "   \"Type_of_work\": \"On-site\",\n",
      "   \"Description\": \"\\\"Developed a Deep Learning solution to detect the presence of Retinal Diseases. The website has been deployed on Google Cloud Platform and available for public use: https://dev-ikshana-dw5whmz2hq-ue.a.run.app/getdata Techstack used: - Docker - Docker Compose - Google Cloud Run - Google Cloud Function - Google Cloud Storage Bucket - Google BigQuery - Convolution-Neural-Networks - Tensorflow - Vanilla Framework (HTML, CSS, Javascript)\\\"\",\n",
      "   \"Skills_Used\": [\n",
      "    \"Team Leadership\",\n",
      "    \"docker\",\n",
      "    \"Web Development\",\n",
      "    \"Google Cloud Platform (GCP)\",\n",
      "    \"TensorFlow\"\n",
      "   ]\n",
      "  },\n",
      "  \"4\": {\n",
      "   \"Company\": \"SS&C Blue Prism\",\n",
      "   \"Role\": \"RPA Developer\",\n",
      "   \"Location\": \"Remote\",\n",
      "   \"Start_Date\": \"Aug 2022\",\n",
      "   \"End_Date\": \"Sep 2022\",\n",
      "   \"Duration\": \"2 mos\",\n",
      "   \"Type_of_work\": null,\n",
      "   \"Description\": \"\\\"I have been a part of the RPA Developer internship offered as part of AICTE's NEAT program. The internship was provided by EduSkills foundation and SS&C Blue Prism University. I learnt about the basics of RPA and Bot development using Blueprism Studio.\\\"\",\n",
      "   \"Skills_Used\": [\n",
      "    \"Analytical Skills\",\n",
      "    \"Blue Prism\",\n",
      "    \"Critical Thinking\",\n",
      "    \"Robotic Process Automation (RPA)\"\n",
      "   ]\n",
      "  }\n",
      " }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_response = chat_session.send_message(\"End chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(final_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkedin_scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
